#!/usr/bin/env bash

echo "BEGIN deploy-cromwell"

## VERIFY REQUIRED VARS ARE DEFINED
# If any env are undefined, try sourcing the setup script and check again.
# Exits if any required var is undefined.
REQUIRED_VARS="
DEPLOYMENT_NAME
INSTALL_DIR
LOGS_DIR
CONFIG_DIR
CROMWELL_PORT
SITE_CROMWELL_JAR
SITE_JTM_GROUP
SITE_CONTAINER_TYPE
SITE_JTM_SCRATCH_DIR
SITE_JTM_WORKER_INSTALL_DIR
CROMWELL_TMPDIR
CROMWELL_WORKFLOW_LOGS_DIR
CROMWELL_EXECUTIONS_DIR
JTM_CONFIG_FILE
INSTALLED_CROMWELL_JAR
"
RESULT=0
for VAR in $REQUIRED_VARS; do
  if [ -z ${!VAR+xxx} ]; then
    echo "Missing env var, $VAR; sourcing setup script..."
    source ./test/integration/define-env
    RESULT=1
    break
  fi
done
if [[ $RESULT -ne 0 ]]; then
  RESULT=0
  for VAR in $REQUIRED_VARS; do
    if [ -z ${!VAR+xxx} ]; then
      echo "Missing env var: $VAR">&2
      RESULT=1
    fi
  done
fi
[ $RESULT -eq 0 ] || exit 1


## COPY CROMWELL JAR
cp "$SITE_CROMWELL_JAR" "$INSTALLED_CROMWELL_JAR" && \
  chgrp "$SITE_JTM_GROUP" "$INSTALLED_CROMWELL_JAR" && \
  chmod 640 "$INSTALLED_CROMWELL_JAR"

CONTAINER_CHECK=""
if [[ "$SITE_CONTAINER_TYPE" == "shifter" ]]; then
  CONTAINER_CHECK="
            LOOKUP=\$(shifterimg lookup \${docker})
            if [[ ! \$LOOKUP ]]; then
                shifterimg pull \${docker}
            fi
"
fi

## GENERATE CONFIG
cat << EOM > $CONFIG_DIR/cromwell.conf
include required(classpath("application"))
webservice
{
  port = $CROMWELL_PORT
}
system
{
  abort-jobs-on-terminate = true
  graceful-server-shutdown = true
  workflow-restart = false
  max-concurrent-workflows = 100000
  max-workflow-launch-count = 100000
  new-workflow-poll-rate = 1
  number-of-workflow-log-copy-workers = 20
  number-of-cache-read-workers = 50
  job-rate-control
  {
    jobs = 1
    per = 1 second
  }
}
workflow-options
{
  workflow-log-dir: "$CROMWELL_WORKFLOW_LOGS_DIR"
  workflow-log-temporary: false
  workflow-failure-mode: "ContinueWhilePossible"
  default
  {
    workflow-type: WDL
    workflow-type-version: "draft-2"
  }
}
call-caching
{
  enabled = false
  invalidate-bad-cache-result = true
}
# this is required for shifter to find image from its registry.
docker {
    hash-lookup {
        enabled = false
    }
}
backend
{
  default = "JTM"
  providers
  {
    JTM
    {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        exit-code-timeout-seconds = 60
        runtime-attributes = """
        String? docker
        String time = "00:30:00"
        Int cpu = 1
        String mem = "5G"
        String cluster = "${JAWS_SITE,,}"
        String poolname = "small"
        String constraint = "$SITE_CLUSTER_CONSTRAINT"
        String qos = "$SITE_CLUSTER_QOS"
        String account = "$SITE_CLUSTER_ACCOUNT"
        Int node = 1
        Int nwpn = 1
        Int shared = 0
        """
        submit = """
            CONSTRAINT="\${constraint}"
            QOS="\${qos}"
            ACCT="\${account}"
            OPT_ARGS=""
            [[ -n \$CONSTRAINT ]] && OPT_ARGS="\$OPT_ARGS -C \$CONSTRAINT"
            [[ -n \$QOS ]] && OPT_ARGS="\$OPT_ARGS --qos \$QOS"
            [[ -n \$ACCT ]] && OPT_ARGS="\$OPT_ARGS -A \$ACCT"
            jtm --config=$JTM_CONFIG_FILE \\
                submit \$OPT_ARGS \\
                -cmd \'/bin/bash \${script}\' \\
                -cl \${cluster} \\
                -t \${time} \\
                -c \${cpu} \\
                -m \${mem} \\
                -p \${poolname} \\
                -N \${node} \\
                -nwpn \${nwpn} \\
                -jid \${job_name} \\
                --shared \${shared}
        """
        kill = "jtm --config=$JTM_CONFIG_FILE kill -tid \${job_id}"
        check-alive = "jtm --config=$JTM_CONFIG_FILE isalive -tid \${job_id}"
        job-id-regex = "JTM task ID (\\\d+)"
        submit-docker = """
            $CONTAINER_CHECK
            CONSTRAINT="\${constraint}"
            QOS="\${qos}"
            ACCT="\${account}"
            OPT_ARGS=""
            [[ -n \$CONSTRAINT ]] && OPT_ARGS="\$OPT_ARGS -C \$CONSTRAINT"
            [[ -n \$QOS ]] && OPT_ARGS="\$OPT_ARGS --qos \$QOS"
            [[ -n \$ACCT ]] && OPT_ARGS="\$OPT_ARGS -A \$ACCT"
            jtm --config=$JTM_CONFIG_FILE \\
                submit \$OPT_ARGS \\
                -cmd \'$SITE_JTM_WORKER_INSTALL_DIR/${SITE_CONTAINER_TYPE}_exec.sh \${docker} \${job_shell} \${script}\' \\
                -cl \${cluster} \\
                -t \${time} \\
                -c \${cpu} \\
                -m \${mem} \\
                -p \${poolname} \\
                -N \${node} \\
                -nwpn \${nwpn} \\
                -jid \${job_name} \\
                --shared \${shared}
        """
        # Root directory where Cromwell writes job results in the container. This value
        # can be used to specify where the execution folder is mounted in the container.
        # it is used for the construction of the docker_cwd string in the submit-docker
        # value above AND in the generation of the "script" file.
        dockerRoot = $CROMWELL_EXECUTIONS_DIR
      }
    }
  }
}
database
{
  profile = "slick.jdbc.MySQLProfile$"
  db
  {
    driver = "com.mysql.cj.jdbc.Driver"
    url = "jdbc:mysql://$SITE_DB_HOST:$SITE_DB_PORT/cromwell_$DEPLOYMENT_NAME?rewriteBatchedStatements=true&useSSL=false&autoReconnect=true&useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC"
    user = "jaws"
    password = "$SITE_DB_PW"
    connectionTimeout = 5000
  }
  insert-batch-size = 2000
}
EOM

chmod 660 "$CONFIG_DIR/cromwell.conf"
chgrp "$SITE_JTM_GROUP" "$CONFIG_DIR/cromwell.conf"


## GENERATE SHIM
cat <<EOM > "$SHIM_DIR/jaws-cromwell-$DEPLOYMENT_NAME"
#!/usr/bin/env bash

export LC_ALL=en_US.UTF-8
export LANG=en_US.UTF-8
export PYTHONIOENCODING=utf-8

$SITE_LOAD_JAVA

# cromwell needs jtm to be in path
source $INSTALL_DIR/jtm/bin/activate

test -d $SITE_JTM_SCRATCH_DIR || mkdir $SITE_JTM_SCRATCH_DIR
cd $SITE_JTM_SCRATCH_DIR
exec java -Xmx5g -Dconfig.file="$CONFIG_DIR/cromwell.conf" -Djava.io.tmpdir="$SITE_CROMWELL_TMPDIR" -jar "$INSTALL_DIR/cromwell.jar" server
EOM
chgrp "$SITE_JTM_GROUP" "$SHIM_DIR/jaws-cromwell-$DEPLOYMENT_NAME"
chmod 770 "$SHIM_DIR/jaws-cromwell-$DEPLOYMENT_NAME"


## GENRATE CONTAINER HELPER SCRIPT
if [ $SITE_CONTAINER_TYPE = "shifter" ]; then
cat <<EOM > "$SITE_JTM_WORKER_INSTALL_DIR/shifter_exec.sh"
#!/usr/bin/env bash
shifter --image=$1 -V $SITE_REF_DATA_DIR:/refdata $2 $3
EOM
  chgrp "$SITE_JTM_GROUP" "$SITE_JTM_WORKER_INSTALL_DIR/shifter_exec.sh"
  chmod 775 "$SITE_JTM_WORKER_INSTALL_DIR/shifter_exec.sh"
elif [ $SITE_CONTAINER_TYPE = "singularity" ]; then
cat <<EOM > "$SITE_JTM_WORKER_INSTALL_DIR/singularity_exec.sh"
#!/bin/bash
export SINGULARITY_CACHEDIR=$SITE_CONTAINERS_DIR
export SINGULARITY_PULLFOLDER=$SITE_CONTAINERS_DIR
export SINGULARITY_TMPDIR=$SITE_CONTAINERS_DIR
export SINGULARITY_LOCALCACHEDIR=$SITE_CONTAINERS_DIR
singularity exec --bind $1:$2 --bind $SITE_REF_DATA_DIR:/refdata docker://$3 $4 $5
exit $?
EOM
  chgrp "$SITE_JTM_GROUP" "$SITE_JTM_WORKER_INSTALL_DIR/singularity_exec.sh"
  chmod 775 "$SITE_JTM_WORKER_INSTALL_DIR/singularity_exec.sh"
fi

printf "END deploy-cromwell\n\n"
